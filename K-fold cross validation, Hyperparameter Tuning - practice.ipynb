{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tpot in ./anaconda3/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.10.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in ./anaconda3/lib/python3.10/site-packages (from tpot) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.2.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in ./anaconda3/lib/python3.10/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.7.3)\n",
      "Requirement already satisfied: deap>=1.2 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in ./anaconda3/lib/python3.10/site-packages (from tpot) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./anaconda3/lib/python3.10/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.10/site-packages (from pandas>=0.24.2->tpot) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.22.0->tpot) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in ./anaconda3/lib/python3.10/site-packages (from update-checker>=0.16->tpot) (2.28.1)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - tpot\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install matplotlib -y\n",
    "%pip install tpot\n",
    "%conda install tpot -y\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation, Hyperparameter Tuning - practice\n",
    "Goal: Create a model using KNN, but use grid search to determine hyperparameters and test with K-fold cross validation (K=10).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is data containing information related to wine and whether it is drinkable.  \n",
    "Predict the type ('target') using KNN and grid search, but achieve at least 99% accuracy (K-fold cross validation, based on K=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0         0    14.23        1.71  2.43               15.6      127.0   \n",
       "1         0    13.20        1.78  2.14               11.2      100.0   \n",
       "2         0    13.16        2.36  2.67               18.6      101.0   \n",
       "3         0    14.37        1.95  2.50               16.8      113.0   \n",
       "4         0    13.24        2.59  2.87               21.0      118.0   \n",
       "..      ...      ...         ...   ...                ...        ...   \n",
       "173       2    13.71        5.65  2.45               20.5       95.0   \n",
       "174       2    13.40        3.91  2.48               23.0      102.0   \n",
       "175       2    13.27        4.28  2.26               20.0      120.0   \n",
       "176       2    13.17        2.59  2.37               20.0      120.0   \n",
       "177       2    14.13        4.10  2.74               24.5       96.0   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     color_intensity   hue  od280/od315_of_diluted_wines  proline  \n",
       "0               5.64  1.04                          3.92   1065.0  \n",
       "1               4.38  1.05                          3.40   1050.0  \n",
       "2               5.68  1.03                          3.17   1185.0  \n",
       "3               7.80  0.86                          3.45   1480.0  \n",
       "4               4.32  1.04                          2.93    735.0  \n",
       "..               ...   ...                           ...      ...  \n",
       "173             7.70  0.64                          1.74    740.0  \n",
       "174             7.30  0.70                          1.56    750.0  \n",
       "175            10.20  0.59                          1.56    835.0  \n",
       "176             9.30  0.60                          1.62    840.0  \n",
       "177             9.20  0.61                          1.60    560.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_wine = datasets.load_wine()\n",
    "wine = pd.DataFrame(raw_wine['data'], index=raw_wine['target'], columns=raw_wine['feature_names'])\n",
    "wine = wine.reset_index(names=['target'] + raw_wine['feature_names'])\n",
    "display(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_columns_names =['target',\n",
    " 'malic_acid',\n",
    " 'ash',\n",
    " 'alcalinity_of_ash',\n",
    " 'magnesium',\n",
    " 'nonflavanoid_phenols',\n",
    " 'proanthocyanins',\n",
    " 'color_intensity',\n",
    " 'hue',\n",
    " 'od280/od315_of_diluted_wines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "X = wine[compact_columns_names]\n",
    "y = wine[\"target\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(wine, test_size=.2, random_state=2)\n",
    "train_X = train[compact_columns_names]\n",
    "train_Y = train[\"target\"]\n",
    "\n",
    "test_X = test[compact_columns_names]\n",
    "test_Y = test[\"target\"]\n",
    "#Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "train_X = scaler.transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X: [[ 1.37386437 -0.93926832 -0.97420996 ...  1.09955402 -1.65599853\n",
      "  -1.49956991]\n",
      " [ 0.07996036  0.05713777  0.19549913 ... -0.78212541 -0.69078402\n",
      "   1.09932487]\n",
      " [ 0.07996036 -0.90336179 -0.24314178 ... -1.43530608  0.49379744\n",
      "   0.84508517]\n",
      " ...\n",
      " [ 0.07996036 -0.60713296 -0.46246223 ... -0.57016612  0.09893695\n",
      "   0.23773476]\n",
      " [-1.21394365 -0.47248348  1.21899459 ...  0.96978302  1.41513857\n",
      "   0.37897904]\n",
      " [ 1.37386437  0.21871714  1.18244118 ...  1.5580782  -0.95402434\n",
      "  -1.1464592 ]]\n",
      " Training Y: 154    2\n",
      "120    1\n",
      "89     1\n",
      "92     1\n",
      "156    2\n",
      "      ..\n",
      "43     0\n",
      "22     0\n",
      "72     1\n",
      "15     0\n",
      "168    2\n",
      "Name: target, Length: 142, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training X: {train_X}\\n Training Y: {train_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "X = wine.iloc[:, :-1].values\n",
    "y = wine.iloc[:, 0].values\n",
    "\n",
    "#Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [2 5 0]\n",
      " [0 1 4]]\n",
      "[Fold no.0]: 83.333%\n",
      "[[6 0 0]\n",
      " [1 6 0]\n",
      " [0 0 5]]\n",
      "[Fold no.1]: 94.444%\n",
      "[[6 0 0]\n",
      " [1 6 0]\n",
      " [0 0 5]]\n",
      "[Fold no.2]: 94.444%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.3]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.4]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.5]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.6]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.7]: 100.000%\n",
      "[[6 0 0]\n",
      " [1 5 1]\n",
      " [0 0 4]]\n",
      "[Fold no.8]: 88.235%\n",
      "[[5 0 0]\n",
      " [1 7 0]\n",
      " [0 0 4]]\n",
      "[Fold no.9]: 94.118%\n",
      "Average accuracy measured by K-fold cross validation: 95.458%\n"
     ]
    }
   ],
   "source": [
    "### With K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Training and Predictions\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluating the Algorithm\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"[Fold no.{fold}]: {accuracy_score(y_test, y_pred)*100:.3f}%\")\n",
    "\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f\"Average accuracy measured by K-fold cross validation: {sum(accs)/len(accs)*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X = wine[compact_columns_names]\n",
    "y = wine[\"target\"]\n",
    "\n",
    "#Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00030878, 0.00022132, 0.00021102, 0.00021122, 0.00021029,\n",
       "        0.00020738, 0.00021045, 0.00021644, 0.00020912, 0.00020838,\n",
       "        0.00021126, 0.00022223, 0.00021265, 0.0002111 ]),\n",
       " 'std_fit_time': array([1.77253798e-04, 1.65250220e-05, 5.00957094e-06, 3.11490019e-06,\n",
       "        2.59646480e-06, 2.45420632e-06, 3.15407145e-06, 5.41876706e-06,\n",
       "        2.90724061e-06, 1.98332160e-06, 3.15479226e-06, 1.58039150e-05,\n",
       "        5.88121178e-06, 2.85744443e-06]),\n",
       " 'mean_score_time': array([0.00058262, 0.00042343, 0.00041029, 0.00040727, 0.00041151,\n",
       "        0.00041063, 0.00041547, 0.00042479, 0.00041692, 0.00041494,\n",
       "        0.00042024, 0.00044274, 0.00043259, 0.00042584]),\n",
       " 'std_score_time': array([2.79539639e-04, 2.32291162e-05, 6.93830837e-06, 5.24607565e-06,\n",
       "        6.86711732e-06, 2.52554945e-06, 5.54157817e-06, 6.90348396e-06,\n",
       "        4.07277277e-06, 5.89448652e-06, 6.05902250e-06, 2.15055673e-05,\n",
       "        6.09176966e-06, 4.87033780e-06]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 12},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 14}],\n",
       " 'split0_test_score': array([0.94444444, 0.88888889, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444]),\n",
       " 'split1_test_score': array([1.        , 1.        , 1.        , 0.88888889, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444]),\n",
       " 'split2_test_score': array([1.        , 0.94444444, 1.        , 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.88888889, 0.94444444, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889]),\n",
       " 'split3_test_score': array([0.94444444, 1.        , 0.94444444, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.94444444, 0.88888889, 0.88888889, 0.88888889]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split5_test_score': array([0.94444444, 0.94444444, 0.94444444, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889]),\n",
       " 'split6_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_score': array([1.        , 1.        , 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.94444444, 0.88888889, 0.94444444, 0.88888889]),\n",
       " 'split8_test_score': array([0.88235294, 0.94117647, 0.88235294, 0.94117647, 0.88235294,\n",
       "        0.88235294, 0.88235294, 0.94117647, 0.88235294, 0.94117647,\n",
       "        0.94117647, 0.88235294, 0.94117647, 0.94117647]),\n",
       " 'split9_test_score': array([1.        , 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.94117647,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_score': array([0.97156863, 0.96601307, 0.96013072, 0.94934641, 0.94901961,\n",
       "        0.94934641, 0.94934641, 0.9496732 , 0.94934641, 0.94379085,\n",
       "        0.9496732 , 0.93267974, 0.94411765, 0.93856209]),\n",
       " 'std_test_score': array([0.03875134, 0.03726637, 0.0370825 , 0.03900406, 0.04000299,\n",
       "        0.04704634, 0.04704634, 0.04619764, 0.04704634, 0.043053  ,\n",
       "        0.03894789, 0.04906751, 0.04304431, 0.04611897]),\n",
       " 'rank_test_score': array([ 1,  2,  3,  6, 10,  6,  6,  4,  6, 12,  4, 14, 11, 13],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([1.     , 0.9875 , 0.98125, 0.9875 , 0.98125, 0.95625, 0.9625 ,\n",
       "        0.95   , 0.95625, 0.9625 , 0.9625 , 0.9625 , 0.95625, 0.9625 ]),\n",
       " 'split1_train_score': array([1.     , 0.9875 , 0.9875 , 0.9625 , 0.975  , 0.96875, 0.95625,\n",
       "        0.95625, 0.95625, 0.95625, 0.96875, 0.9625 , 0.9625 , 0.95625]),\n",
       " 'split2_train_score': array([1.     , 0.9875 , 0.98125, 0.96875, 0.975  , 0.96875, 0.9625 ,\n",
       "        0.9625 , 0.9625 , 0.9625 , 0.96875, 0.96875, 0.96875, 0.95625]),\n",
       " 'split3_train_score': array([1.     , 0.9875 , 0.98125, 0.975  , 0.975  , 0.95625, 0.95625,\n",
       "        0.95   , 0.95   , 0.94375, 0.95625, 0.95   , 0.9625 , 0.95625]),\n",
       " 'split4_train_score': array([1.     , 0.9875 , 0.9875 , 0.9875 , 0.975  , 0.9625 , 0.95625,\n",
       "        0.94375, 0.94375, 0.95   , 0.95   , 0.95625, 0.95625, 0.94375]),\n",
       " 'split5_train_score': array([1.     , 0.9875 , 0.9875 , 0.975  , 0.96875, 0.975  , 0.9625 ,\n",
       "        0.95625, 0.9625 , 0.96875, 0.975  , 0.98125, 0.9875 , 0.975  ]),\n",
       " 'split6_train_score': array([1.     , 0.9875 , 0.98125, 0.975  , 0.98125, 0.95625, 0.9625 ,\n",
       "        0.95   , 0.94375, 0.95   , 0.95625, 0.95625, 0.95   , 0.94375]),\n",
       " 'split7_train_score': array([1.     , 0.98125, 0.975  , 0.98125, 0.975  , 0.9625 , 0.95   ,\n",
       "        0.95625, 0.95625, 0.95625, 0.95   , 0.95625, 0.95625, 0.9375 ]),\n",
       " 'split8_train_score': array([1.        , 0.99378882, 0.99378882, 0.98757764, 0.98136646,\n",
       "        0.95652174, 0.95031056, 0.94409938, 0.95652174, 0.95031056,\n",
       "        0.95652174, 0.95652174, 0.95652174, 0.95031056]),\n",
       " 'split9_train_score': array([1.        , 0.98757764, 0.97515528, 0.98136646, 0.9689441 ,\n",
       "        0.95652174, 0.95652174, 0.9378882 , 0.95031056, 0.94409938,\n",
       "        0.95031056, 0.9378882 , 0.96273292, 0.93167702]),\n",
       " 'mean_train_score': array([1.        , 0.98751165, 0.98314441, 0.97814441, 0.97565606,\n",
       "        0.96192935, 0.95755823, 0.95069876, 0.95380823, 0.95444099,\n",
       "        0.95943323, 0.95881599, 0.96192547, 0.95132376]),\n",
       " 'std_train_score': array([0.        , 0.00280386, 0.00561008, 0.00804196, 0.00435992,\n",
       "        0.00647908, 0.00462113, 0.00699379, 0.00636723, 0.00786727,\n",
       "        0.00845737, 0.01081584, 0.00984882, 0.01204623])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "grid_vals = {'n_neighbors': [1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14]}\n",
    "grid_knn = GridSearchCV(estimator=classifier, param_grid=grid_vals, scoring='accuracy', \n",
    "                       cv=kfold, refit=True, return_train_score=True) \n",
    "\n",
    "# Training and Prediction\n",
    "grid_knn.fit(X, y)\n",
    "\n",
    "# Evaluating the Algorithm\n",
    "display(grid_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.0]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.1]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.2]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.3]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.4]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.5]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.6]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.7]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 4]]\n",
      "[Fold no.8]: 100.000%\n",
      "[[5 0 0]\n",
      " [0 8 0]\n",
      " [0 0 4]]\n",
      "[Fold no.9]: 100.000%\n",
      "Average accuracy measured by K-fold cross validation (best model): 100.000%\n"
     ]
    }
   ],
   "source": [
    "# Best estimator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    y_pred = grid_knn.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluating the Algorithm\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"[Fold no.{fold}]: {accuracy_score(y_test, y_pred)*100:.3f}%\")\n",
    "\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f\"Average accuracy measured by K-fold cross validation (best model): {sum(accs)/len(accs)*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
